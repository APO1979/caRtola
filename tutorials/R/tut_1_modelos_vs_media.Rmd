---
title: "TUT2 - Modelos de regressão são melhores que a média?"
author: "Henrique Gomide"
date: "`r Sys.Date()`"
output: html_document
---

## Motivação

Olá pessoal!

No tutorial anterior, vimos que a média é um indicador limitado para mitar no cartola. Vamos tentar neste tutorial, usar outros modelos e reduzir o risco na tomada de decisão. Começaremos de forma básica, com um modelo de regressão linear. O número a ser batido aqui é RMSE = 4.171413 (lembrando: valores menores são melhores).

<center>![Levy Fidélix - Vamos subir o nível disso aqui](http://geradormemes.com/media/created/n931gu.jpg)</center>

Este tutorial também é dedicado a _iniciantes_ do R e análise de dados. 

### Pacotes

Iremos usar o [Caret](http://caret.r-forge.r-project.org) pacote do R que facilita horrores o desenvolvimento de modelos preditivos. Existem inúmeros tutoriais sobre o pacote, além disso até [artigo científico](https://www.jstatsoft.org/article/view/v028i05) publicado no Jounal of Statistical Software.

```{r, setup, include = FALSE}
library(devtools)    # Carregar função para descrever pacotes e descrição do R
library(ggplot2)     # Plotar gráficos
library(ggthemes)    # Carregar tema adicional para os gráficos
library(dplyr)       # Funções para manipulação dos dados 
library(caret)       # Pacote para modelar os dados
```


### Banco de dados

Usaremos os dados do [Cartola](https://github.com/henriquepgomide/caRtola/tree/master/db). Assim como no primeiro tutorial, iremos segmentar nosso banco em metades. Mas antes, vamos carregar os dados.

```{r}
# Carregar banco de dados
cartola <- read.csv("../../db/cartola_aggregated.csv", stringsAsFactors = FALSE)
```


## Plano de Análise

1. Segmentar o banco de dados
2. Desenvolver diferentes modelos de regressão
3. Comparar o desempenho destes modelos com nosso Benchmark - a média.

## Análise

### Segmentar o banco de dados
```{r}
# Segmentar banco de dados
treino <- cartola %>%
  filter(!(Rodada == 20 & ano == 2017))

validacao <- cartola %>%
  filter(Rodada == 20 & ano == 2017)

# Selecionar somente algumas variáveis
variaveis <- c("AtletaID", "variable", "Posicao", "Pontos", "PontosMedia", "ClubeID")

treino <- treino[, variaveis]
validacao <-  validacao[, variaveis]

# Controles para os modelos
## Regression Models
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 1, allowParallel = TRUE, verboseIter = TRUE)
## Random Forest
rfGrid <-  expand.grid(mtry = c(10,20,40,80))   
```

## Visualizações

Antes de começarmos precisamos conduzir análises exploratórias para termos uma ideia de quais variáveis podem estar ligadas à pontuação do cartola (atletas.pontos_num). Para isso, inspecionaremos as variáveis:

* AtletaID - Nome completo do time
* Posicao - Posição do jogador
* variable - Jogo aconteceu em casa ou fora

### Times
```{r, fig.height=40}
ggplot(data = treino, aes(y = Pontos, x = 1)) + 
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) + 
  geom_jitter(width = .8, alpha = .5, colour = "#7cb5ec") +
  theme_hc() + facet_wrap(~ClubeID, nrow = 21, shrink = FALSE) + coord_flip() + 
  labs(title = "Distribuição das médias por time", x = "Time", y = "Média")
```


### Atletas por posição

```{r, fig.height=20}
ggplot(data = treino, aes(y = Pontos, x = 1)) + 
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) + 
  geom_jitter(width = .8, alpha = .5, colour = "#7cb5ec") +
  theme_hc() + facet_wrap(~Posicao, nrow = 6, shrink = FALSE) + coord_flip() + 
  labs(title = "Distribuição das médias por posição", x = "Posição", y = "Média")
```


### Times vs. casa

```{r, fig.height=20}
ggplot(data = treino, aes(y = Pontos, factor(variable))) + 
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) + 
  geom_jitter(width = .3, alpha = .3, colour = "#7cb5ec") +
  theme_hc() + facet_wrap(~ClubeID, ncol = 3) +
  labs(title = "Distribuição das médias por time e casa", x = "", y = "Pontuação")
```

### Gols e pontuação

```{r}
ggplot(data = treino, aes(y = Pontos, factor(variable))) + 
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) + 
  geom_jitter(width = .3, alpha = .3, colour = "#7cb5ec") +
  theme_hc() + facet_wrap(~ ClubeID, ncol = 3) +
  labs(title = "Distribuição das médias por time e casa", x = "", y = "Pontuação")
```

## Modelagem

### Análise de regressão linear simples
```{r, results=FALSE, echo = FALSE, warning=FALSE}
glmModel_0  <- train(Pontos ~ variable + Posicao + PontosMedia + ClubeID, data = treino, 
                     method="glm", metric = "RMSE", preProcess = c("knnImpute","scale", "center"),
                     trControl = ctrl, na.action = na.omit)
```

```{r}
predictions <- predict(glmModel_0, newdata = validacao)
postResample(pred = predictions, obs = validacao$Pontos)
```


### EXtreme Gradient Boosting

```{r, results=FALSE, echo = FALSE, warning=FALSE}
boostTree_0  <- train(Pontos ~ variable + Posicao + PontosMedia + ClubeID, data = treino, 
                     method="xgbTree", metric = "RMSE", preProcess = c("scale", "center"),
                     trControl = ctrl, na.action = na.omit)
```

```{r}
predictions_boost <- predict(boostTree_0, newdata = validacao)
postResample(pred = predictions_boost, obs = validacao$Pontos)
```

## Comentário

Com apenas 4 variáveis fizemos progresso. Baixamos o RMSE em aproximadamente meio ponto, usando qualquer um dos modelos. Do ponto de vista de produção, podemos ficar com o modelo de regressão linear por enquanto. No entanto, ainda temos trabalho diversos pontos de melhora para nossos modelos, entre eles:

1. Separar os scouts de defesa e ataque
2. Criar modelos que predizem os resultados dos jogos
3. Criar modelos que atribuem força ao ataque e a defesa dos times
4. Criar variável sofreu gol no jogo, já que é uma defesa que não leva gols, ganha pontos de recompensa.

